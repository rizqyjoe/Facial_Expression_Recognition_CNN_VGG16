{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qfja9tMaB1ZH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizqyjoe/Facial_Expression_Recognition_CNN_VGG16/blob/main/Model6/2_done.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeVby1efCap-",
        "outputId": "19a10c3b-07b8-43c6-a834-b9f62f7b138b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKtKDUJ3MeFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888573ae-2236-43b4-cf4b-94a829e09cde"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from IPython.display import SVG, Image\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4WU1TDXMrBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d4a768-e29b-47df-e88d-b07a2d106c34"
      },
      "source": [
        "img_size = 48\n",
        "batch_size = 64\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, horizontal_flip=True)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/drive/MyDrive/Dataset/fer2013/train/\", \n",
        "                                                    target_size = (img_size, img_size),\n",
        "                                                    color_mode = 'grayscale',\n",
        "                                                    batch_size = batch_size,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle = True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\"/content/drive/MyDrive/Dataset/fer2013/test/\", \n",
        "                                                  target_size = (img_size, img_size),\n",
        "                                                  color_mode = 'grayscale',\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  shuffle = True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28739 images belonging to 7 classes.\n",
            "Found 7198 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaphOXryNHD0"
      },
      "source": [
        "CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWMZlPNZYntO",
        "outputId": "d048e69f-cc92-454d-e0e5-e09b51e67971"
      },
      "source": [
        "!pip install keras_applications\n",
        "!pip install keras_vggface"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 30.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 35.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n",
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.7/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (7.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (1.4.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (2.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqGeyQsUM1yz"
      },
      "source": [
        "from keras.engine import  Model\n",
        "from keras.layers import Flatten, Dense, Input\n",
        "from keras_vggface.vggface import VGGFace\n",
        "\n",
        "#custom parameters\n",
        "nb_class = 7\n",
        "hidden_dim = 512\n",
        "\n",
        "vgg_model = VGGFace(include_top=False, input_shape=(img_size, img_size, 3))\n",
        "last_layer = vgg_model.get_layer('pool5').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
        "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
        "\n",
        "model = Model(vgg_model.input, out)\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAMiFQPiYyJQ",
        "outputId": "9c0acbb5-88d3-4220-f742-19860d70c962"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv1_1 (Conv2D)             (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv1_2 (Conv2D)             (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2_1 (Conv2D)             (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2_2 (Conv2D)             (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv3_1 (Conv2D)             (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv3_2 (Conv2D)             (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv3_3 (Conv2D)             (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv4_1 (Conv2D)             (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv4_2 (Conv2D)             (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv4_3 (Conv2D)             (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv5_1 (Conv2D)             (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv5_2 (Conv2D)             (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv5_3 (Conv2D)             (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc6 (Dense)                  (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "fc7 (Dense)                  (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "fc8 (Dense)                  (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 15,243,591\n",
            "Trainable params: 15,243,591\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHiJKznUNF4m"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQwjJzJNC3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "bfb87e12-de7f-49f3-de91-da88860a785c"
      },
      "source": [
        "epochs = 15\n",
        "steps_per_epoch = train_generator.n // train_generator.batch_size\n",
        "validation_steps = test_generator.n // test_generator.batch_size\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"Model4_vggface-finetuning_Adam0.001.h5\", monitor='val_accuracy',\n",
        "                            save_weights_only = True,\n",
        "                            mode = 'max',\n",
        "                            verbose = 1)\n",
        "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=3, verbose=1)\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(\"model.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, checkpointer]\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=validation_steps,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7ed8c6c96467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  input depth must be evenly divisible by filter depth: 1 vs 3\n\t [[node model_1/conv1_1/Relu (defined at <ipython-input-15-7ed8c6c96467>:19) ]] [Op:__inference_train_function_2214]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ24KGTfNOVS"
      },
      "source": [
        "#Visualizing the training\n",
        "epochs = epochs\n",
        "metric = \"loss\"\n",
        "metric2 = \"accuracy\"\n",
        "train_m1 = history.history[metric]\n",
        "train_m2 = history.history[metric2]\n",
        "val_m1 = history.history[f'val_{metric}']\n",
        "val_m2 = history.history[f'val_{metric2}']\n",
        "\n",
        "fig_model = make_subplots(1,\n",
        "                          2,\n",
        "                          subplot_titles=(f\"{metric.capitalize()} over Time\",\n",
        "                                          f\"{metric2.capitalize()} over Time\"))\n",
        "fig_model.add_trace(go.Scatter(x=np.arange(epochs),\n",
        "                               y=train_m1,\n",
        "                               mode=\"lines+markers\",\n",
        "                               name=f\"Training {metric.capitalize()}\"),\n",
        "                    row=1,\n",
        "                    col=1)\n",
        "fig_model.add_trace(go.Scatter(x=np.arange(epochs),\n",
        "                               y=val_m1,\n",
        "                               mode=\"lines+markers\",\n",
        "                               name=f\"Validation {metric.capitalize()}\"),\n",
        "                    row=1,\n",
        "                    col=1)\n",
        "\n",
        "fig_model.add_trace(go.Scatter(x=np.arange(epochs),\n",
        "                               y=train_m2,\n",
        "                               mode=\"lines+markers\",\n",
        "                               name=f\"Training {metric2.capitalize()}\"),\n",
        "                    row=1,\n",
        "                    col=2)\n",
        "fig_model.add_trace(go.Scatter(x=np.arange(epochs),\n",
        "                               y=val_m2,\n",
        "                               mode=\"lines+markers\",\n",
        "                               name=f\"Validation {metric2.capitalize()}\"),\n",
        "                    row=1,\n",
        "                    col=2)\n",
        "fig_model.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}